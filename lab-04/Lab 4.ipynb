{"cells":[{"cell_type":"markdown","id":"93795a2a","metadata":{"id":"93795a2a"},"source":["# Lab 4: Image Classification in Pytorch - Feedforward Fully Connected Neural Network [CIFAR-10]\n"," **See handout-05:** https://frcs.github.io/4C16-LectureNotes/\n","\n","In this lab, you will train a Fully Connected Deep Neural Network to do classification on a dataset of 50,000 images with 10 classes.\n","\n","The aim of this lab is for you to:\n","1. become familiar with PyTorch\n","2. experiment with the many concepts discussed in class. eg. try different hyperparameters, try different architectures, see the effect of dropout, etc.\n","\n","\n"]},{"cell_type":"markdown","id":"qXSDQg9-HGTU","metadata":{"id":"qXSDQg9-HGTU"},"source":["## Note: Enabling GPU  \n","\n","By default, Colab runs CPU only. To change to GPU mode, go to Runtime>Change runtime type, select \"hardware accelerator\" to GPU.\n","\n","This will restart your instance (obviously), so everytime you do this you'll need to start your again from the start of the notebook.\n","\n","Beware that GPU instances are not always available. Also, Google might restrict your usage. Google doesn't have clear rules on this.\n","\n","So be mindful and **only use GPU instances for training. Use CPU only for development and tinkering.**\n","\n","\n","\n"]},{"cell_type":"code","execution_count":null,"id":"5L-2lbZ0pyVO","metadata":{"id":"5L-2lbZ0pyVO"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/gdrive')\n","%cd /content/gdrive/MyDrive/4c16-labs/code/lab-04/"]},{"cell_type":"markdown","id":"OEfo45qBwOP8","metadata":{"id":"OEfo45qBwOP8"},"source":["# 1. Import Required Libraries"]},{"cell_type":"code","execution_count":16,"id":"d57d4722","metadata":{"id":"d57d4722","executionInfo":{"status":"ok","timestamp":1760540539510,"user_tz":-60,"elapsed":2,"user":{"displayName":"Dylan Neve","userId":"01431218930135572833"}}},"outputs":[],"source":["import os\n","import pickle                                     # Used for unpacking our imported python dataset\n","import importlib\n","import urllib.request                             # Used for fetching data from URLs\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","from matplotlib.ticker import MaxNLocator\n","import numpy as np\n","from tqdm.auto import tqdm                        # Used for progress bars\n","import sklearn.model_selection                    # Helper function for splitting datasets\n","from IPython.display import clear_output\n","\n","import torch                                      # The main PyTorch library\n","import torch.nn as nn                             # Contains pytorch network building blocks (e.g., layers)\n","import torch.nn.functional as F                   # Contains functions for neural network operations (e.g., activation functions)\n","from torch.utils.data import Dataset, DataLoader  # Utilities for datasets and data loaders\n","from torchsummary import summary                  # Used for printing PyTorch model summary"]},{"cell_type":"markdown","id":"tSlzM-C4qVDk","metadata":{"id":"tSlzM-C4qVDk"},"source":["# 2. Loading the Dataset\n","\n","To load the dataset, the standard practice is to create a `Dataset` class.\n","\n","We make our own class by inheriting from `torch.utils.data.Dataset`. This gives PyTorch a standard way to get data.\n","\n","What we do in a custom `Dataset`:\n","- `__init__`: load or prepare the whole data once (e.g. download, read file, basic preprocessing).\n","- `__len__`: tell how many samples we have.\n","- `__getitem__(index)`: return ONE sample (inputs, label) at the given position.\n","\n","Why bother?\n","- PyTorch's `DataLoader` builtin class can automatically, from our `Dataset`,  give us mini-batches, shuffle the data, and use workers (multiple CPU threads) processes for speed leaving the GPU free to train.\n","- Keeps data loading code separate from the model code, making things cleaner.\n","- Easy to later add transforms (e.g. random crop, flip) inside `__getitem__`.\n","\n"]},{"cell_type":"code","execution_count":null,"id":"10c5b9a6","metadata":{"id":"10c5b9a6"},"outputs":[],"source":["class CIFAR10Dataset(Dataset):\n","    \"\"\"Custom CIFAR-10 dataset from provided pickle file.\n","    Handles download (if missing), train/val split, normalization, tensor conversion.\n","    \"\"\"\n","    def __init__(self, url, pkl_path, train=True, test_size=0.1, random_state=42):\n","        super().__init__()\n","        data_dir = os.path.dirname(pkl_path)\n","        os.makedirs(data_dir, exist_ok=True)\n","        if not os.path.exists(pkl_path):\n","            print(f'Downloading dataset to {pkl_path} ...')\n","\n","            urllib.request.urlretrieve(url, pkl_path)\n","            print('Download complete.')\n","        print('Loading dataset...')\n","        with open(pkl_path, 'rb') as f:\n","            data = pickle.load(f)\n","        print('Loaded.')\n","        # loading the input images\n","        # images are rescaled from 0..255 to 0..1\n","        X = data['X'].astype('float32') / 255.0\n","        # loading the Ground Truth classes\n","        Y = data['Y'].astype('int64')\n","        if Y.ndim > 1:  # ensure labels are 1D\n","            Y = np.squeeze(Y)\n","        self.labels = data['labels']\n","        self.num_classes = len(self.labels)\n","        # random split of the data into training set and validation set\n","        X_train, X_val, y_train, y_val = sklearn.model_selection.train_test_split(\n","            X, Y, test_size=test_size, random_state=random_state\n","        )\n","        # casting numpy data to torch data\n","        if train:\n","            self.X = torch.from_numpy(X_train)\n","            self.y = torch.from_numpy(y_train)\n","        else:\n","            self.X = torch.from_numpy(X_val)\n","            self.y = torch.from_numpy(y_val)\n","        self.y = self.y.long().view(-1)\n","        # permuting dimensions to PyTorch conventions (N,C,H,W)\n","        self.X = self.X.permute(0, 3, 1, 2)\n","        self.len = self.X.shape[0]\n","    def __getitem__(self, idx):\n","        return self.X[idx], self.y[idx]\n","    def __len__(self):\n","        return self.len"]},{"cell_type":"markdown","id":"U52dIdoivct3","metadata":{"id":"U52dIdoivct3"},"source":["# 3. Instantiate the training and validation dataset classes"]},{"cell_type":"code","execution_count":null,"id":"0f2bd03d","metadata":{"id":"0f2bd03d"},"outputs":[],"source":["# Path to the classification dataset\n","datset_url = 'https://tcddeeplearning.blob.core.windows.net/deeplearning202324/cifar10-dataset.pkl'\n","# Path to your lab 4 Drive directory on the Colab VM\n","lab_4_dir = '/home/tcd/Downloads/cifar10-dataset.pkl'\n","\n","trainset = CIFAR10Dataset(datset_url, lab_4_dir, train=True)\n","valset = CIFAR10Dataset(datset_url, lab_4_dir, train=False)\n","print('Train size:', len(trainset), ' Val size:', len(valset))\n"]},{"cell_type":"markdown","id":"583vhvoMwE5V","metadata":{"id":"583vhvoMwE5V"},"source":["# 4. Visualize Sample Images"]},{"cell_type":"code","execution_count":null,"id":"387f4fe1","metadata":{"id":"387f4fe1"},"outputs":[],"source":["plt.figure(figsize=(6,4))\n","for i in range(24):\n","    img, lab = trainset[i]\n","    plt.subplot(4,6,i+1)\n","    plt.imshow(img.permute(1,2,0))\n","    plt.axis('off')\n","    plt.title(trainset.labels[lab])\n","plt.tight_layout()\n","plt.show()\n","\n","\n","# We know, the images are very small, but keep in mind that we need to\n","# process 50,000 of these!"]},{"cell_type":"markdown","id":"nIdv4sIvwUp-","metadata":{"id":"nIdv4sIvwUp-"},"source":["# 5. Now, go to `models.py` and define your own Feedforward Neural Network (FCN) model here\n","\n","You will define your own Feedforward Neural Network model using PyTorch's `nn.Module`. This network will take the flattened CIFAR-10 images as input and output scores for each of the 10 classes. We have provided a dummy class that will run without modification as a baseline.\n","\n","For a comprehensive list of PyTorch building blocks, see: https://docs.pytorch.org/docs/stable/nn.html\n","\n","In this lab, we are focusing only on fully connected/Linear/Dense layers as the trainable layers, but you may use different normalisation, dropout, activation, etc layers.\n","\n"]},{"cell_type":"code","execution_count":19,"id":"4930a39f","metadata":{"id":"4930a39f","executionInfo":{"status":"ok","timestamp":1760540656866,"user_tz":-60,"elapsed":1,"user":{"displayName":"Dylan Neve","userId":"01431218930135572833"}}},"outputs":[],"source":["from models import SimpleNN"]},{"cell_type":"markdown","id":"d0339955","metadata":{"id":"d0339955"},"source":["# 6. Check your model shape and size\n","\n","The model must not exceed 5M trainable parameters.\n","\n","For fully connected (linear) layers, the number of trainable parameters is calculated as:\n","\n","\n","\n","$$\n","\\text{#params} =  \n","\\text{#previous_features} \\times \\text{#neurons_in_current_layer} + \\text{#neurons_in_current_layer (for biases)}\n","$$"]},{"cell_type":"code","execution_count":18,"id":"b0f6535c","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"b0f6535c","outputId":"a64185c2-d870-4658-abb3-06679ea450fc","executionInfo":{"status":"ok","timestamp":1760540546372,"user_tz":-60,"elapsed":25,"user":{"displayName":"Dylan Neve","userId":"01431218930135572833"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Using device: cuda\n","----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","           Flatten-1                 [-1, 3072]               0\n","            Linear-2                   [-1, 32]          98,336\n","            Linear-3                   [-1, 10]             330\n","================================================================\n","Total params: 98,666\n","Trainable params: 98,666\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 0.01\n","Forward/backward pass size (MB): 0.02\n","Params size (MB): 0.38\n","Estimated Total Size (MB): 0.41\n","----------------------------------------------------------------\n","Trainable parameters: 98666\n"]}],"source":["# device refers to the GPU or the CPU, depending whether GPU is available.\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print('Using device:', device)\n","\n","# Call our model. The number of output classes is passed as an argument.\n","# Re-import the SimpleNN\n","# We need to always re-import the SimpleNN after importlib reload as autoreload do not work in Google Colab as per https://github.com/googlecolab/colabtools/issues/5580.\n","# If you work without Google Colab, you will not need this.\n","importlib.reload(models)\n","from models import SimpleNN\n","\n","model = SimpleNN(num_classes=trainset.num_classes).to(device)\n","\n","# display information about the model\n","summary(model, (3,32,32))\n","\n","params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n","print('Trainable parameters:', params)\n","if params > 5_000_000:\n","    raise Exception('Your model is unecessarily complex, scale down!')"]},{"cell_type":"markdown","id":"RHbL3d1g0wwO","metadata":{"id":"RHbL3d1g0wwO"},"source":["# 7.  Monitoring\n","\n","\n","Don't edit this cell 😺"]},{"cell_type":"code","execution_count":null,"id":"c0b986a6","metadata":{"id":"c0b986a6"},"outputs":[],"source":["# Custom callback for plotting loss and accuracy during training\n","\n","class PlotLogAccuracy:\n","\n","  def __init__(self):\n","    self.epochs = []\n","    self.train_losses = []\n","    self.val_losses = []\n","    self.train_acc = []\n","    self.val_acc = []\n","    self.epoch_count = 0\n","\n","  def update(self, train_loss, train_acc, val_loss, val_acc):\n","    self.epochs.append(self.epoch_count)\n","    self.train_losses.append(train_loss)\n","    self.val_losses.append(val_loss)\n","    self.train_acc.append(train_acc)\n","    self.val_acc.append(val_acc)\n","    self.epoch_count += 1\n","\n","    clear_output(wait=True)\n","    plt.figure(figsize=(16, 6))\n","    plt.subplot(121)\n","    plt.plot(self.epochs, self.train_losses, label=\"train loss\")\n","    plt.plot(self.epochs, self.val_losses, label=\"validation loss\")\n","    plt.gca().xaxis.set_major_locator(MaxNLocator(integer=True))\n","    plt.ylabel('loss')\n","    plt.xlabel('epoch')\n","    plt.title('Model Loss')\n","    plt.legend()\n","    plt.subplot(122)\n","    plt.plot(self.epochs, self.train_acc, label=\"training accuracy\")\n","    plt.plot(self.epochs, self.val_acc, label=\"validation accuracy\")\n","    plt.legend()\n","    plt.ylabel('accuracy')\n","    plt.xlabel('epoch')\n","    plt.title('Model Accuracy')\n","    plt.gca().xaxis.set_major_locator(MaxNLocator(integer=True))\n","    plt.show();"]},{"cell_type":"markdown","id":"cFQEBTImyUDk","metadata":{"id":"cFQEBTImyUDk"},"source":["# 8. Optimiser and Dataloader Hyperparameter Setup\n","\n","Here we define the dataloaders which handle the dataset, and the training optimiser.\n","\n","Their hyperparameters include (but are not limited to):\n","\n","\n","*   Number of training epochs\n","*   Batch size\n","* Learning rate (step size)\n","* Optimiser momentum\n","* Dataset shuffling\n","\n","Remember from class that the optimiser sets the weights and biases of the network during training. [Many exist](https://docs.pytorch.org/docs/stable/optim.html).\n"]},{"cell_type":"code","execution_count":null,"id":"b37b3415","metadata":{"id":"b37b3415"},"outputs":[],"source":["epochs = 10           # shorter for notebook demo - increase for training\n","batch_size = 64       # play with this\n","learning_rate = 0.01  # play with this\n","momentum = 0.9        # play with this\n","\n","criterion = nn.CrossEntropyLoss()\n","\n","# Reload SimpleNN\n","importlib.reload(models)\n","from models import SimpleNN\n","\n","# setting the model (calling this again will reset the weights)\n","model = SimpleNN(num_classes=trainset.num_classes).to(device)\n","\n","# play with this\n","optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=momentum)\n","\n","trainloader = DataLoader(trainset, batch_size=batch_size, shuffle=True,\n","                         num_workers=0, pin_memory=torch.cuda.is_available())\n","valloader   = DataLoader(valset, batch_size=batch_size, shuffle=False,\n","                         num_workers=0, pin_memory=torch.cuda.is_available())\n","\n","plotter = PlotLogAccuracy()\n","\n","train_loss_hist, val_loss_hist = [], []\n","train_acc_hist, val_acc_hist = [], []\n","\n","print('Setup complete.')"]},{"cell_type":"markdown","id":"7GSa4PwH1Hot","metadata":{"id":"7GSa4PwH1Hot"},"source":["# 9. Training and Validation\n","\n","The following cell contains the main training and validation loop for the neural network.\n","\n"]},{"cell_type":"code","execution_count":null,"id":"049e3ba7","metadata":{"id":"049e3ba7"},"outputs":[],"source":["print('Starting training...')\n","\n","# Epoch Loop: It iterates through the specified number of training epochs.\n","\n","for epoch in range(epochs):\n","\n","    # For each epoch, all data in the dataset is processed.\n","\n","    model.train() # Sets the model to training mode\n","\n","    running_loss, correct, total = 0.0, 0, 0 # resetting loss/accuracy metrics\n","\n","    #  Iterates through the `trainloader` to get mini-batches of data\n","    for x_batch, y_batch in tqdm(trainloader, desc=f'Epoch {epoch+1}/{epochs} [Train]', leave=False):\n","\n","        # copying data to the GPU (the `device`) if GPU is available\n","        x_batch, y_batch = x_batch.to(device), y_batch.to(device).view(-1)\n","\n","        optimizer.zero_grad()           # setting up gradient to zero\n","        out = model(x_batch)            # Performs the forward pass\n","        loss = criterion(out, y_batch)  # calculates the loss\n","        loss.backward()                 # performs backpropagation in parallel on the batch\n","        optimizer.step()                # optimizer steps to update the model's weights\n","\n","        # updating current training Loss and Accuracy on the mini-batch\n","        running_loss += loss.item() * x_batch.size(0)\n","        preds = out.argmax(1)\n","        total += y_batch.size(0)\n","        correct += (preds == y_batch).sum().item()\n","\n","    train_loss = running_loss / len(trainloader.dataset)\n","    train_acc = correct / total\n","\n","    # Computing Validation Loss and Accuracy\n","\n","    model.eval() # switching model to eval mode, disabling dropout/batchnorm/other custom modules\n","    val_running_loss, val_correct, val_total = 0.0, 0, 0\n","    with torch.no_grad(): # we disable gradient computation to save some memory\n","        for x_batch, y_batch in tqdm(valloader, desc=f'Epoch {epoch+1}/{epochs} [Val]', leave=False):\n","            x_batch, y_batch = x_batch.to(device), y_batch.to(device).view(-1)\n","            out = model(x_batch)\n","            loss = criterion(out, y_batch)\n","            val_running_loss += loss.item() * x_batch.size(0)\n","            preds = out.argmax(1)\n","            val_total += y_batch.size(0)\n","            val_correct += (preds == y_batch).sum().item()\n","    val_loss = val_running_loss / len(valloader.dataset)\n","    val_acc = val_correct / val_total\n","\n","    # Record training loss and accuracy\n","    train_loss_hist.append(train_loss); val_loss_hist.append(val_loss)\n","    train_acc_hist.append(train_acc); val_acc_hist.append(val_acc)\n","\n","    # At the end of the epoch, plot loss and accuracy for training/validation\n","    plotter.update(train_loss, train_acc, val_loss, val_acc)\n","    print(f'Epoch {epoch+1}: Train Loss {train_loss:.4f} Acc {train_acc:.4f} | Val Loss {val_loss:.4f} Acc {val_acc:.4f}')\n","\n","print('Training finished.')\n"]},{"cell_type":"markdown","id":"42CWygzN3FP5","metadata":{"id":"42CWygzN3FP5"},"source":["# 10. Save your model to your lab 4 directory."]},{"cell_type":"code","execution_count":14,"id":"976ea6d7","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"976ea6d7","outputId":"8b7ef6f4-b2b6-4908-9b15-79a64a7bd3a7","executionInfo":{"status":"ok","timestamp":1760540445670,"user_tz":-60,"elapsed":31,"user":{"displayName":"Dylan Neve","userId":"01431218930135572833"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Model saved to model.pth\n"]}],"source":["MODEL_PATH = 'model.pth'  # DO NOT CHANGE THE NAME, this is required by the evaluation script\n","\n","# Save the entire model\n","torch.save(model, os.path.join('/content/gdrive/MyDrive/4c16-labs/code/lab-04', MODEL_PATH))\n","print('Model saved to', MODEL_PATH)\n"]},{"cell_type":"markdown","id":"J07a6D2p3NRS","metadata":{"id":"J07a6D2p3NRS"},"source":["# 11. Load and test your model\n","\n","Note: we will evaluate your model on a different dataset. This cell is to demonstrate model loading and give you a rough idea of your model performance.\n"]},{"cell_type":"code","execution_count":15,"id":"e60c22c6","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"e60c22c6","outputId":"84d5af25-8b55-4be5-ebab-2cab815d5a22","executionInfo":{"status":"ok","timestamp":1760540447689,"user_tz":-60,"elapsed":190,"user":{"displayName":"Dylan Neve","userId":"01431218930135572833"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Reloaded Model - Val Loss: 1.3331, Val Acc: 0.5634\n"]}],"source":["loaded = torch.load(MODEL_PATH, map_location=device, weights_only=False)\n","loaded.eval()\n","val_loss_sum, val_correct, val_total = 0.0, 0, 0\n","with torch.no_grad():\n","    for x_batch, y_batch in valloader:\n","        x_batch, y_batch = x_batch.to(device), y_batch.to(device).view(-1)\n","        out = loaded(x_batch)\n","        loss = criterion(out, y_batch)\n","        val_loss_sum += loss.item() * x_batch.size(0)\n","        preds = out.argmax(1)\n","        val_total += y_batch.size(0)\n","        val_correct += (preds == y_batch).sum().item()\n","final_val_loss = val_loss_sum / len(valloader.dataset)\n","final_val_acc = val_correct / val_total\n","print(f'Reloaded Model - Val Loss: {final_val_loss:.4f}, Val Acc: {final_val_acc:.4f}')"]},{"cell_type":"markdown","id":"HB_RJQIB65oG","metadata":{"id":"HB_RJQIB65oG"},"source":["# Lab Objective: Design a network only using Dense layers and achieve 50% or more accuracy on the server's test set\n","\n","You may want to test the following:\n","\n","*   Adding layers\n","*   Changing the number of units per layer\n","*   Changing the activation functions\n","*   Changing the optimizer\n","*   The learning rate\n","*   Adding Dropout\n","*   Adding Regularisers\n","\n","Always check on your accuray and loss graphs that that you are not overfitting.\n","\n","You don't need to go mad, we know you can get 55% accuracy with only 3 Dense layers.\n","Also note that Deeper networks will require longer training times.\n","\n","Good luck!\n","\n","---\n","\n","**F.A.Q.**\n","\n","*   **I reached 51% on my validation set, but the submission didn't pass, how come?**\n","    > The test set on the server is different from your validation set.\n","*   **Can I use convolutional layers?**\n","    > No."]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.18"}},"nbformat":4,"nbformat_minor":5}